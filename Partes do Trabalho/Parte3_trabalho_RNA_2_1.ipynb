{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parte3-trabalho-RNA-2.1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b6SIKiRSwBs"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import math\n",
        "import random\n",
        "from tabulate import tabulate\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7wDUN9jTDDD"
      },
      "source": [
        "!wget https://www.dropbox.com/s/8l7ced95mb4k9ds/dataAll.txt\n",
        "!wget https://www.dropbox.com/s/jad0ciovllm7y2y/data1.txt\n",
        "!wget https://www.dropbox.com/s/mnzqvzttfan3r3f/dataHoldout.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFb-i_9TUSj6"
      },
      "source": [
        "class Neuronio:\n",
        "  #As variáveis do neurônio\n",
        "  #(Aqui ficam os elementos gerais da classe)\n",
        "  #(Para acessá-las, use self.[variável])\n",
        "  bias = -1\n",
        "  degrau = 0\n",
        "  taxa_aprendizado = 0.1\n",
        "  taxa_inicial = [-0.5, 0.5]\n",
        "\n",
        "  def __init__(self, exemplos):\n",
        "    #As variáveis dos exemplos\n",
        "    #(Aqui ficam os elementos individuais de cada objeto)\n",
        "    \n",
        "    self.exemplos=exemplos\n",
        "    '''\n",
        "    Embaralhando os dados em função da separação dos dados para o método Holdout\n",
        "    tendo em vista que não atrapalará nos resultados das outras questões:\n",
        "    '''\n",
        "    np.random.shuffle(self.exemplos)\n",
        "\n",
        "  \n",
        "    #Extraindo os resultados esperados\n",
        "    self.resultados_esperados = np.zeros(len(self.exemplos))\n",
        "    for i in range(len(self.exemplos)):\n",
        "      self.resultados_esperados[i] = self.exemplos[i][-1]\n",
        "\n",
        "    #Agora criaremos um outro array com o bias no ínicio e sem o valor esperado\n",
        "    self.exemplos_bias = np.zeros_like(self.exemplos, dtype=np.float64)\n",
        "    \n",
        "    for i in range(len(self.exemplos)):\n",
        "      for j in range(len(self.exemplos[i])):\n",
        "        self.exemplos_bias[i][0] = self.bias\n",
        "        self.exemplos_bias[i][1] = self.exemplos[i][0]\n",
        "        self.exemplos_bias[i][2] = self.exemplos[i][1]\n",
        "\n",
        "      \n",
        "    self.ajustes = 0\n",
        "    #variável auxiliar para contar os ajustes\n",
        "    self.aux = 0\n",
        "    self.epocas = 0\n",
        "    self.resultados_algoritmo = np.zeros(len(self.exemplos_bias))\n",
        "\n",
        "    #Variáveis auxiliares para o método holdout:\n",
        "    self.exemplos_treinamento =self.exemplos[:int(len(self.exemplos)*70/100)]\n",
        "    self.exemplos_teste = self.exemplos[int(len(self.exemplos)*70/100):]\n",
        "\n",
        "    self.exemplos_bias_treinamento =self.exemplos_bias[:int(len(exemplos)*70/100)]\n",
        "    self.exemplos_bias_teste = self.exemplos_bias[int(len(exemplos)*70/100):]\n",
        "\n",
        "    self.resultados_algoritmo_treinamento = np.zeros(len(self.exemplos_bias_treinamento))\n",
        "    self.resultados_algoritmo_teste = np.zeros(len(self.exemplos_bias_teste))\n",
        "\n",
        "    self.resultados_esperados_treinamento =self.resultados_esperados[:int(len(self.exemplos)*70/100)]\n",
        "    self.resultados_esperados_teste = self.resultados_esperados[int(len(self.exemplos)*70/100):]\n",
        "\n",
        "    #Definindo o tamanho da lista de pesos\n",
        "    self.pesos = np.zeros(len(self.exemplos_bias[0]), dtype=np.float64)\n",
        "\n",
        "    for i in range(len(self.pesos)):\n",
        "        self.pesos[i] = random.uniform(-0.5,0.5)\n",
        "\n",
        "    #PESOS DE TESTE\n",
        "    #self.pesos = np.array([-0.5441,0.5562,-0.4074])\n",
        "\n",
        "    print(\"Pesos iniciais:\")\n",
        "    m = np.array([self.pesos])\n",
        "    header = [\"bias\",\"x1\",\"x2\"]\n",
        "    table = tabulate(m,header,tablefmt=\"fancy_grid\")\n",
        "    print(table)\n",
        "\n",
        "\n",
        "  def ativacao_degrau(self,u):\n",
        "    '''\n",
        "    Função de Ativação Degrau:\n",
        "    (degrau = θ)\n",
        "    Se u for maior ou igual a θ, retorna 1\n",
        "    Caso contrário, retorna 0\n",
        "    '''\n",
        "    if(u >= self.degrau):\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "\n",
        "  def teste(self):\n",
        "    '''\n",
        "    Precisamos testar se os valores coincidem com o gabarito\n",
        "    retorna: \n",
        "    - True,  se coincidir com o gabarito\n",
        "    - False, se não coincidir \n",
        "    '''\n",
        "    j = 0\n",
        "    for i in self.exemplos_bias:\n",
        "      #u = bias*pesos[0] + x1*pesos[1]... + xn*pesos[n]\n",
        "      u = i[0]*self.pesos[0]+i[1]*self.pesos[1]+i[2]*self.pesos[2]\n",
        "      self.resultados_algoritmo[j] = self.ativacao_degrau(u)        \n",
        "      j +=1\n",
        "\n",
        "    for i in range(len(self.resultados_algoritmo)):\n",
        "      if(self.resultados_algoritmo[i] != self.resultados_esperados[i]):\n",
        "          return False\n",
        "    return True\n",
        "\n",
        "  def ajuste(self):\n",
        "    '''\n",
        "    Faz o ajuste de pesos usando a Regra Delta\n",
        "    '''\n",
        "  \n",
        "    self.aux = 0\n",
        "    for i in range(len(self.exemplos_bias)):\n",
        "      for j in range(len(self.pesos)):\n",
        "        #Regra Delta\n",
        "        erro = self.resultados_esperados[i] - self.resultados_algoritmo[i]\n",
        "        self.pesos[j] = self.pesos[j] + self.taxa_aprendizado*erro*self.exemplos_bias[i][j]\n",
        "      \n",
        "      # Se o erro for diferente de zero, significa que os resultados não convergiram\n",
        "      # Portanto, os pesos precisam ser atualizados\n",
        "\n",
        "    \n",
        "      if (erro != 0):\n",
        "        self.ajustes +=1\n",
        "        self.aux +=1\n",
        "        m = np.array([self.pesos])\n",
        "\n",
        "    \n",
        "    #Print de informações\n",
        "    print(\"Na época:\",self.epocas,\"Houve\",self.aux,\"ajuste(s)\")\n",
        "    print(\"Pesos ajustados:\")\n",
        "    header = [\"bias\",\"x1\",\"x2\"]\n",
        "    table = tabulate(m,header,tablefmt=\"fancy_grid\")\n",
        "    print(table)\n",
        "      \n",
        "    \n",
        "\n",
        "  def treinamento(self):\n",
        "    '''\n",
        "    Treina o algoritmo até a convergência\n",
        "    '''\n",
        "    \n",
        "    while (not self.teste()):\n",
        "      self.epocas += 1\n",
        "      self.ajuste()\n",
        "      \n",
        "    \n",
        "    #Na última época, o self.teste retorna True, e portanto o while não é ativado\n",
        "    #Os pesos estão certos, mas é preciso adicionar 1 ao contador de épocas\n",
        "    self.epocas += 1\n",
        "\n",
        "    #Em um problema com convergência, A última época sempre tem 0 ajustes\n",
        "    print(\"Na época:\",self.epocas,\"Houve\",0,\"ajuste(s)\")\n",
        "\n",
        "    print('---')    \n",
        "    print(\"Total de Ajustes:\", self.ajustes)\n",
        "    print(\"Total de Épocas:\", self.epocas)\n",
        "    print(\"Pesos finais:\")\n",
        "    m = np.array([self.pesos])\n",
        "    header = [\"bias\",\"x1\",\"x2\"]\n",
        "    table = tabulate(m,header,tablefmt=\"fancy_grid\")\n",
        "    print(table)\n",
        "\n",
        "  #Funções para o método Holdout:\n",
        "\n",
        "  def comparacao_treinamento(self):\n",
        "    '''\n",
        "    Testando os valores do gabarito com o treinamento:\n",
        "    '''\n",
        "    j = 0\n",
        "    for i in self.exemplos_bias_treinamento:\n",
        "      #u = bias*pesos[0] + x1*pesos[1]... + xn*pesos[n]\n",
        "      u = i[0]*self.pesos[0]+i[1]*self.pesos[1]+i[2]*self.pesos[2]\n",
        "      self.resultados_algoritmo_treinamento[j] = self.ativacao_degrau(u)        \n",
        "      j +=1\n",
        "\n",
        "    for i in range(len(self.resultados_algoritmo_treinamento)):\n",
        "      if(self.resultados_algoritmo_treinamento[i] != self.resultados_esperados_treinamento[i]):\n",
        "          return False\n",
        "    return True\n",
        "\n",
        "      #Treinando o neurônio com 70% dos dados\n",
        "  def treinamento_holdout(self):\n",
        "\n",
        "    self.epocas=0\n",
        "    for i in range(100):\n",
        "      self.comparacao_treinamento()\n",
        "      self.epocas += 1\n",
        "      self.ajuste_holdout()\n",
        "      \n",
        "    print(\"Na época:\",self.epocas,\"Houve\",0,\"ajuste(s)\")\n",
        "\n",
        "    print('---')    \n",
        "    print(\"Total de Ajustes:\", self.ajustes)\n",
        "    print(\"Total de Épocas:\", self.epocas)\n",
        "    print(\"Pesos finais:\")\n",
        "    m = np.array([self.pesos])\n",
        "    header = [\"bias\",\"x1\",\"x2\"]\n",
        "    table = tabulate(m,header,tablefmt=\"fancy_grid\")\n",
        "    print(table)\n",
        "\n",
        "  #função de ajuste de treinamento:\n",
        "  def ajuste_holdout(self):\n",
        "    '''\n",
        "    Faz o ajuste de pesos usando a Regra Delta\n",
        "    '''\n",
        "  \n",
        "    self.aux = 0\n",
        "    for i in range(len(self.exemplos_bias_treinamento)):\n",
        "      for j in range(len(self.pesos)):\n",
        "        #Regra Delta\n",
        "        erro = self.resultados_esperados_treinamento[i] - self.resultados_algoritmo_treinamento[i]\n",
        "        self.pesos[j] = self.pesos[j] + self.taxa_aprendizado*erro*self.exemplos_bias_treinamento[i][j]\n",
        "    \n",
        "      if (erro != 0):\n",
        "        self.ajustes +=1\n",
        "        self.aux +=1\n",
        "        m = np.array([self.pesos])\n",
        "\n",
        "    \n",
        "    #Print de informações\n",
        "    print(\"Na época:\",self.epocas,\"Houve\",self.aux,\"ajuste(s)\")\n",
        "    print(\"Pesos ajustados:\")\n",
        "    header = [\"bias\",\"x1\",\"x2\"]\n",
        "    table = tabulate(m,header,tablefmt=\"fancy_grid\")\n",
        "    print(table)\n",
        "      \n",
        "      #Função de teste para os 20% dos dados que não foram utilizados no treino\n",
        "  def teste_holdout(self):\n",
        "    '''\n",
        "    Precisamos testar se os valores coincidem com o gabarito\n",
        "    retorna: \n",
        "    - True,  se coincidir com o gabarito\n",
        "    - False, se não coincidir \n",
        "    '''\n",
        "    j = 0\n",
        "    for i in self.exemplos_bias_teste:\n",
        "      #u = bias*pesos[0] + x1*pesos[1]... + xn*pesos[n]\n",
        "      u = i[0]*self.pesos[0]+i[1]*self.pesos[1]+i[2]*self.pesos[2]\n",
        "      self.resultados_algoritmo_teste[j] = self.ativacao_degrau(u)        \n",
        "      j +=1\n",
        "      \n",
        "    return self.resultados_algoritmo_teste\n",
        "\n",
        "  \n",
        "  def grafico(self):\n",
        "    #coordenadas dos pontos + cor\n",
        "    x = np.zeros(len(self.exemplos), dtype=np.float64)\n",
        "    y = x.copy()\n",
        "    cor = []\n",
        "\n",
        "    for i in range(len(self.exemplos)):\n",
        "      x[i] = self.exemplos[i][0]\n",
        "      y[i] = self.exemplos[i][1]\n",
        "\n",
        "      if(self.resultados_algoritmo[i] == 1):\n",
        "        cor.append('blue')\n",
        "      else:\n",
        "        cor.append('red')\n",
        "\n",
        "    #função da linha\n",
        "    minimo = x.min() or y.min()\n",
        "    maximo = x.max() and y.max()\n",
        "    valor1 = self.pesos[0]/self.pesos[2]\n",
        "    valor2 = self.pesos[1]/self.pesos[2]\n",
        "    x2 = np.linspace(minimo -1,maximo + 1, 100)\n",
        "    y2 = valor1 - valor2*x2    \n",
        "\n",
        "    #gráfico em sí\n",
        "    plt.rcParams['figure.figsize'] = [10, 8]\n",
        "    plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "    plt.xlabel(\"X1\")\n",
        "    plt.ylabel(\"X2\")\n",
        "    plt.scatter(x,y, marker='o',color=cor)\n",
        "    plt.plot(x2, y2)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "  def getPesos(self):\n",
        "     return self.pesos\n",
        "  \n",
        "  def getExemplos_Bias(self):\n",
        "     return self.exemplos_bias\n",
        "  \n",
        "\n",
        "  def getResultados_Algoritmo(self):\n",
        "     return self.resultados_algoritmo\n",
        "\n",
        "Teste1 = Neuronio(array_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewoRLn7JPs9J"
      },
      "source": [
        "#Parte 3: Validação Holdout e problema não linearmente separável"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXNCs_wXYj2_"
      },
      "source": [
        "##Representação visual: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAKj3BwmYtwU"
      },
      "source": [
        "##Treinamento e teste:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jIeOf2SX77b"
      },
      "source": [
        "array_ho = np.fromfile(\"/content/dataHoldout.txt\")\n",
        "array_ho = array_ho.ravel()\n",
        "'''\n",
        "O array vem na forma (N,1), N = número de dados total.\n",
        "Para organizar por cada exemplo, precisamos mudar a forma da array.\n",
        "Cada exemplo deve ter o formato [x1,x2,yd], pois são 3 dados para cada\n",
        "Então o array deve ficar com 3 colunas.\n",
        "O número de linhas deve ser N/colunas.\n",
        "'''\n",
        "colunas = 3\n",
        "array_ho = array_ho.reshape(len(array_ho)//colunas, colunas)\n",
        "exemplo = np.array([[2,2,1],[4,4,0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jojRecT8t5-m"
      },
      "source": [
        "Teste1.treinamento_holdout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_ptZPInY8Cq"
      },
      "source": [
        "#Resultados verdadeiros do conjunto teste:\n",
        "Teste1.resultados_esperados_teste"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIs8AexrZG44"
      },
      "source": [
        "#Resultados previstos do conjunto teste:\n",
        "Teste1.teste_holdout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmQxl7rQZRKO"
      },
      "source": [
        "##Metricas:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6DtCDAlZYf-"
      },
      "source": [
        "###**1.** Matriz confusão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoQch7xRZd5m"
      },
      "source": [
        "cm = confusion_matrix(Teste1.resultados_esperados_teste, Teste1.resultados_algoritmo_teste)\n",
        "cmap=plt.cm.Reds\n",
        "normalize = False\n",
        "classes =  [1,0]\n",
        "plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation=45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "\n",
        "fmt = '.2f' if normalize else 'd'\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, format(cm[i, j], fmt))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pNqlheXZlm9"
      },
      "source": [
        "### Métricas gerais:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu08egmwMCa0"
      },
      "source": [
        "print(classification_report(Teste1.resultados_esperados_teste, Teste1.resultados_algoritmo_teste))\n",
        "confusion_matrix(Teste1.resultados_esperados_teste, Teste1.resultados_algoritmo_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fys4kqQQZ4rt"
      },
      "source": [
        "###**2.** Acurácia = 0.15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvknZYY9aJMj"
      },
      "source": [
        "### **3.**\n",
        "#### Precisão = 0.16 \n",
        "#### Revocação = 0.71\n",
        "#### F1-Score = 0.26"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoDXCBVcaqbi"
      },
      "source": [
        "##**4.**\n",
        "\n",
        "A partir dessas métricas, podemos perceber que o neurônio não conseguiu prever corretamente os dados utilizando o método Holdout.\n",
        "Um dos principais motivos é do problema não ser linearmente separável, como evidenciado no gráfico (x), isso dificulta a previsão pois não terá uma solução satisfatória para um modelo que tenta dividir os dados linearmente.\n",
        "\n",
        "Também temos a questão da acurácia, mesmo com o problema da não linearidade, estar muito baixa. Esse problema provavelmente se dá ao número baixo de épocas determinado que não deu tempo para o modelo se ajustar adequadamente. "
      ]
    }
  ]
}